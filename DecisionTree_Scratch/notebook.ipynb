{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec278b3-38cb-4961-b79d-673d0f9151b2",
   "metadata": {},
   "source": [
    "## Node Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c2bf8f7-0fab-429c-bd3e-fc56c7467ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a96272f-6c9d-43ca-841e-52e9ab7bbd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index  # Index of the feature to split on\n",
    "        self.threshold = threshold            # Threshold value for the split\n",
    "        self.left = left                      # Left child node\n",
    "        self.right = right                    # Right child node\n",
    "        self.value = value                    # Class label for leaf nodes\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.value is not None  # Check if the node is a leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3a1b3-b9fd-4a6a-be4e-e6b42303fa7f",
   "metadata": {},
   "source": [
    "## Tree Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6072417-75b9-4856-b9a6-d445232d90d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier():\n",
    "    def __init__(self, max_depth=100, min_samples_split=2):\n",
    "        ''' \n",
    "        Constructor for the MyDecisionTreeClassifier.\n",
    "        Parameters:\n",
    "        - max_depth: The maximum depth of the tree (to prevent overfitting)\n",
    "        - min_samples_split: The minimum number of samples required to split a node\n",
    "        '''\n",
    "        np.random.seed(10)\n",
    "        self.root = None  # Initialize the root of the tree\n",
    "        self.min_samples_split = min_samples_split  # Minimum samples required to split\n",
    "        self.max_depth = max_depth  # Maximum depth of the tree\n",
    "\n",
    "    def is_finished(self, depth):\n",
    "        ''' \n",
    "        Determine if the tree construction should stop based on certain conditions.\n",
    "        Parameters:\n",
    "        - depth: Current depth of the tree\n",
    "        Returns:\n",
    "        - True if any stopping condition is met, otherwise False\n",
    "        '''\n",
    "        if depth >= self.max_depth or self.n_class_labels == 1 or self.n_samples < self.min_samples_split:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        ''' \n",
    "        Recursively build the decision tree.\n",
    "        Parameters:\n",
    "        - X: Features of the training dataset\n",
    "        - y: Labels of the training dataset\n",
    "        - depth: Current depth of the tree (default is 0)\n",
    "        Returns:\n",
    "        - A Node representing the root of the constructed subtree\n",
    "        '''\n",
    "        self.n_samples, self.n_features = X.shape  # Get the number of samples and features\n",
    "        self.n_class_labels = len(np.unique(y))     # Get the number of unique class labels\n",
    "\n",
    "        # Check stopping criteria\n",
    "        if self.is_finished(depth):\n",
    "            # Assign the most common label to the leaf node\n",
    "            most_common_label = np.argmax(np.bincount(y))\n",
    "            return Node(value=most_common_label)\n",
    "\n",
    "        # Find the best feature and threshold to split on\n",
    "        rnd_feats = np.random.choice(self.n_features, self.n_features, replace=False)\n",
    "        best_feat, best_thresh = self.best_split(X, y, rnd_feats)\n",
    "\n",
    "        # Split the dataset into left and right nodes\n",
    "        left_idx, right_idx = self.create_split(X[:, best_feat], best_thresh)\n",
    "        left_child = self.build_tree(X[left_idx, :], y[left_idx], depth + 1)\n",
    "        right_child = self.build_tree(X[right_idx, :], y[right_idx], depth + 1)\n",
    "\n",
    "        # Create and return a node for the current best split\n",
    "        return Node(best_feat, best_thresh, left_child, right_child)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        ''' \n",
    "        Fit the model to the training data.\n",
    "        Parameters:\n",
    "        - X: Features of the training dataset\n",
    "        - y: Labels of the training dataset\n",
    "        '''\n",
    "        # Encode the labels using LabelEncoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "        # Build the decision tree using the encoded labels\n",
    "        self.root = self.build_tree(X, y_encoded)\n",
    "\n",
    "    def entropy(self, y):\n",
    "        ''' \n",
    "        Calculate the entropy of the labels.        \n",
    "        Parameters:\n",
    "        - y: Labels of the dataset\n",
    "        Returns:\n",
    "        - The entropy value\n",
    "        '''\n",
    "        # Calculate the proportions of each class\n",
    "        proportions = np.bincount(y) / len(y)\n",
    "        # Compute entropy\n",
    "        entropy = -np.sum([p * np.log2(p) for p in proportions if p > 0])\n",
    "        return entropy\n",
    "\n",
    "    def create_split(self, X, threshold):\n",
    "        ''' \n",
    "        Create a split of the dataset based on the threshold.\n",
    "        Parameters:\n",
    "        - X: Feature values to split\n",
    "        - threshold: Threshold value to use for splitting\n",
    "        Returns:\n",
    "        - Indices of the left and right splits\n",
    "        '''\n",
    "        left_idx = np.argwhere(X <= threshold).flatten()  # Indices for left split\n",
    "        right_idx = np.argwhere(X > threshold).flatten()   # Indices for right split\n",
    "        return left_idx, right_idx\n",
    "        \n",
    "    def information_gain(self, X, y, threshold):\n",
    "        ''' \n",
    "        Calculate the information gain from a split.\n",
    "        Parameters:\n",
    "        - X: Feature values to split\n",
    "        - y: Labels of the dataset\n",
    "        - threshold: Threshold value for the split\n",
    "        Returns:\n",
    "        - Information gain from the split\n",
    "        '''\n",
    "        parent_loss = self.entropy(y)  # Calculate entropy before the split\n",
    "        left_idx, right_idx = self.create_split(X, threshold)  # Create split\n",
    "\n",
    "        n, n_left, n_right = len(y), len(left_idx), len(right_idx)\n",
    "        if n_left == 0 or n_right == 0: \n",
    "            return 0  # No gain if one of the splits is empty\n",
    "\n",
    "        # Calculate child loss based on the left and right splits\n",
    "        child_loss = (n_left / n) * self.entropy(y[left_idx]) + (n_right / n) * self.entropy(y[right_idx])\n",
    "        return parent_loss - child_loss  # Return the information gain\n",
    "\n",
    "    def best_split(self, X, y, features):\n",
    "        ''' \n",
    "        Find the best feature and threshold to split on.\n",
    "        Parameters:\n",
    "        - X: Features of the training dataset\n",
    "        - y: Labels of the training dataset\n",
    "        - features: Randomly selected features to consider for the split\n",
    "        Returns:\n",
    "        - Best feature index and threshold value\n",
    "        '''\n",
    "        best_split = {'score': -1, 'threshold': None, 'feature': None}\n",
    "\n",
    "        for feature in features:\n",
    "            X_feature = X[:, feature]  # Get the feature values for the current feature\n",
    "            thresholds = np.unique(X_feature)  # Unique threshold values for the feature\n",
    "\n",
    "            for thresh in thresholds:\n",
    "                score = self.information_gain(X_feature, y, thresh)  # Calculate information gain\n",
    "                if best_split['score'] < score:  # Update best split if score is higher\n",
    "                    best_split['score'] = score\n",
    "                    best_split['threshold'] = thresh\n",
    "                    best_split['feature'] = feature\n",
    "                \n",
    "        return best_split['feature'], best_split['threshold']  # Return the best feature and threshold\n",
    "\n",
    "    def traverse_tree(self, x, node):\n",
    "        ''' \n",
    "        Traverse the tree to make a prediction for a given input sample.\n",
    "        Parameters:\n",
    "        - x: Input sample to predict\n",
    "        - node: Current node in the tree\n",
    "        Returns:\n",
    "        - Predicted class label for the input sample\n",
    "        '''\n",
    "        if node.is_leaf():\n",
    "            return node.value  # Return the label of the leaf node\n",
    "\n",
    "        # Decide to traverse left or right based on the feature value\n",
    "        if x[node.feature_index] <= node.threshold:  \n",
    "            return self.traverse_tree(x, node.left)  # Traverse left\n",
    "        return self.traverse_tree(x, node.right)  # Traverse right\n",
    "\n",
    "    def predict(self, X):\n",
    "        ''' \n",
    "        Predict class labels for a set of input samples.\n",
    "        Parameters:\n",
    "        - X: Features of the input samples\n",
    "        Returns:\n",
    "        - Array of predicted class labels\n",
    "        '''\n",
    "        predictions = [self.traverse_tree(x, self.root) for x in X]  # Make predictions for all samples\n",
    "        return np.array(predictions)  # Return as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60669dbc-f507-41a5-9f88-14b7b07d02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy_score(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f627cf-6a36-438a-9fdb-5ef1d9d24591",
   "metadata": {},
   "source": [
    "# Prediction on Iris dataset\n",
    "### Using My Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a9a1dab-5d2a-4452-b361-060d38d747c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Iris.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f4c8e9b-dbd3-4299-bfd8-9a2a865150b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "[5.1 3.5 1.4 0.2]\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, 1:-1].values\n",
    "Y = data.iloc[:, -1].values\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f7194937-fb15-4b04-9e4d-324c14441eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7cc251e0-9f3e-40b2-83a7-b4afb8af7656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(120,)\n",
      "(30, 4)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6c84639-97e9-46a3-b705-72f31f0fef8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Accuracy (Iris dataset):       96.67 %\n"
     ]
    }
   ],
   "source": [
    "classifier = MyDecisionTreeClassifier(max_depth=120)\n",
    "classifier.fit(X_train, y_train)\n",
    "my_pred = classifier.predict(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_test = label_encoder.fit_transform(y_test)\n",
    "my_acc_iris = my_accuracy_score(y_test, my_pred)\n",
    "print(f\"My Accuracy (Iris dataset):       {my_acc_iris*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dfe938-0a2b-4e96-b733-2732f3d39af0",
   "metadata": {},
   "source": [
    "### Using Sk-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a61e340-0096-4512-96cb-467b45ff1f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sk-Learn Accuracy (Iris dataset):       90.00 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=41)\n",
    "iris_cls = DecisionTreeClassifier(max_depth=10)\n",
    "iris_cls.fit(X_train, y_train)\n",
    "pred = iris_cls.predict(X_test)\n",
    "\n",
    "acc_iris = accuracy_score(y_test, pred)\n",
    "print(f\"Sk-Learn Accuracy (Iris dataset):       {acc_iris*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e72b3ad0-0eb0-4143-9c43-ed54b6a95420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Accuracy (Iris dataset):             96.67 %\n",
      "Sk-Learn Accuracy (Iris dataset):       90.00 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"My Accuracy (Iris dataset):             {my_acc_iris*100:.2f} %\")\n",
    "print(f\"Sk-Learn Accuracy (Iris dataset):       {acc_iris*100:.2f} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
